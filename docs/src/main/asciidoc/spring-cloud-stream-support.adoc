== Spring Cloud Stream Support

Spring Cloud Stream is a framework for building highly scalable event-driven microservices connected with shared messaging systems.

The framework provides a flexible programming model built on already established and familiar Spring idioms and best practices, including support for persistent pub/sub semantics, consumer groups, and stateful partitions.

Current binder implementations include:

* spring-cloud-azure-stream-binder-eventhubs
* spring-cloud-azure-stream-binder-servicebus

=== Spring Cloud Stream Binder for Azure Event Hubs

==== Dependency Setup

[source,xml]
----
<dependency>
	<groupId>com.azure.spring</groupId>
	<artifactId>spring-cloud-azure-stream-binder-eventhubs</artifactId>
</dependency>
----

==== Configuration

The binder provides the following configuration options in `application.properties`.

===== Spring Cloud Azure Properties

[cols="<,<,<,<"]
|===
|Name |Description |Required |Default

|spring.cloud.azure.auto-create-resources |If enable auto-creation for Azure resources | |false
|spring.cloud.azure.region |Region name of the Azure resource group, e.g. westus |Yes if spring.cloud.azure.auto-create-resources is enabled. 
|spring.cloud.azure.environment |Azure Cloud name for Azure resources, supported values are `azure`, `azurechina`, `azure_germany` and `azureusgovernment` which are case insensitive | |azure 
|spring.cloud.azure.client-id |Client (application) id of a service principal or Managed Service Identity (MSI) |Yes if service principal or MSI is used as credential configuration. 
|spring.cloud.azure.client-secret |Client secret of a service principal |Yes if service principal is used as credential configuration. 
|spring.cloud.azure.msi-enabled |If enable MSI as credential configuration |Yes if MSI is used as credential configuration. |false
|spring.cloud.azure.resource-group |Name of Azure resource group |Yes if service principal or MSI is used as credential configuration. 
|spring.cloud.azure.subscription-id |Subscription id of an MSI |Yes if MSI is used as credential configuration. 
|spring.cloud.azure.tenant-id |Tenant id of a service principal |Yes if service principal is used as credential configuration. 
|spring.cloud.azure.eventhub.connection-string |Event Hubs Namespace connection string |Yes if connection string is used as Event Hubs credential configuration 
|spring.cloud.azure.eventhub.checkpoint-storage-account |StorageAccount name for message checkpoint |Yes
|spring.cloud.azure.eventhub.checkpoint-access-key |StorageAccount access key for message checkpoint |Yes if StorageAccount access key is used as StorageAccount credential configuration
|spring.cloud.azure.eventhub.checkpoint-container |StorageAccount container name for message checkpoint |Yes
|spring.cloud.azure.eventhub.namespace |Event Hub Namespace. Auto creating if missing |Yes if service principal or MSI is used as credential configuration. 
|===

===== Common Producer Properties

You can use the producer configurations of *Spring Cloud Stream*,
it uses the configuration with the format of `spring.cloud.stream.bindings.&lt;channelName&gt;.producer`.

====== Partition configuration

The system will obtain the parameter `PartitionSupply` to send the message,
the following is the process of obtaining the priority of the partition ID and key:

image:https://user-images.githubusercontent.com/13167207/142611562-38dfd834-47e6-4b8c-ba7d-b811f88a2821.png[Create PartitionSupply parameter process]

The following are configuration items related to the producer:

*_partition-count_*

The number of target partitions for the data, if partitioning is enabled.

Default: 1

*_partition-key-extractor-name_*

The name of the bean that implements `PartitionKeyExtractorStrategy`.
The partition handler will first use the `PartitionKeyExtractorStrategy#extractKey` method to obtain the partition key value.

Default: null

*_partition-key-expression_*

A SpEL expression that determines how to partition outbound data.
When interface `PartitionKeyExtractorStrategy` is not implemented, it will be called in the method `PartitionHandler#extractKey`.

Default: null

For more information about setting partition for the producer properties, please refer to the https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html#_producer_properties[Producer Properties of Spring Cloud Stream].

===== Event Hub Producer Properties

It supports the following configurations with the format of `spring.cloud.stream.eventhubs.bindings.&lt;channelName&gt;.producer`.

*_sync_*

Whether the producer should act in a synchronous manner with respect to writing messages into a stream. If true, the
producer will wait for a response from Event Hub after a send operation.

Default: `false`

*_send-timeout_*

Effective only if `sync` is set to true. The amount of time to wait for a response from Event Hub after a send operation, in milliseconds.

Default: `10000`

===== Common Consumer Properties

You can use the below consumer configurations of *Spring Cloud Stream*,
it uses the configuration with the format of `spring.cloud.stream.bindings.&lt;channelName&gt;.consumer`.

====== Batch Consumer

When `spring.cloud.stream.bindings.&lt;binding-name&gt;.consumer.batch-mode` is set to `true`, all of the received events
will be presented as a `List&lt;?&gt;` to the consumer function. Otherwise, the function will be called with one event at a time.
The size of the batch is controlled by Event Hubs consumer properties `max-size`(required) and `max-wait-time`
(optional); refer to the <<event-hub-consumer-properties,below section>> for more information.

*_batch-mode_*

Whether to enable the entire batch of messages to be passed to the consumer function in a `List`.

Default: `False`

===== Event Hub Consumer Properties

It supports the following configurations with the format of `spring.cloud.stream.eventhubs.bindings.&lt;channelName&gt;.consumer`.

*_start-position_*

Whether the consumer receives messages from the beginning or end of event hub. if `EARLIEST`, from beginning. If
`LATEST`, from end.

Default: `LATEST`

*_checkpoint-mode_*

The mode in which checkpoints are updated.

`RECORD`, `default` mode. Checkpoints occur after each record is successfully processed by user-defined message
handler without any exception. If you use `StorageAccount` as checkpoint store, this might become bottleneck.

`BATCH`, checkpoints occur after each batch of messages successfully processed by user-defined message handler
without any exception. Be aware that batch size could be any value and `BATCH` mode is only supported when consume
batch
mode is set true.

`MANUAL`, checkpoints occur on demand by the user via the `Checkpointer`. You can do checkpoints after the message has been successfully processed. `Message.getHeaders.get(AzureHeaders.CHECKPOINTER)`callback can get you the `Checkpointer` you need. Please be aware all messages in the corresponding Event Hub partition before this message will be considered as successfully processed.

`PARTITION_COUNT`, checkpoints occur after the count of messages defined by `checkpoint_count` successfully processed for each partition. You may experience reprocessing at most `checkpoint_count` of when message processing fails.

`Time`, checkpoints occur at fixed time interval specified by `checkpoint_interval`. You may experience reprocessing of messages during this time interval when message processing fails.

Default: `RECORD`

----
Notes: when consume batch mode is false(default value), `BATCH` checkpoint mode is not invalid.
----

*_checkpoint-count_*

Effectively only when `checkpoint-mode` is `PARTITION_COUNT`. Decides the amount of message for each partition to do one checkpoint.

Default: `10`

*_checkpoint-interval_*

Effectively only when `checkpoint-mode` is `Time`. Decides The time interval to do one checkpoint.

Default: `5s`

*_max-size_*

The maximum number of events that will be in the list of a message payload when the consumer callback is invoked.

Default: `10`

*_max-wait-time_*

The max time `Duration` to wait to receive a batch of events up to the max batch size before invoking the consumer callback.

Default: `null`

for full configurations, check appendix

==== Basic Usage

==== Samples

==== Error Channels

*_consumer error channel_*

this channel is open by default, you can handle the error message in this way:

----
    // Replace destination with spring.cloud.stream.bindings.input.destination
    // Replace group with spring.cloud.stream.bindings.input.group
    @ServiceActivator(inputChannel == "{destination}.{group}.errors")
    public void consumerError(Message<?> message) {
        LOGGER.error("Handling customer ERROR: " + message);
    }
----

*_producer error channel_*

this channel is not open by default, if you want to open it. You need to add a configuration in your application.properties, like this:

----
spring.cloud.stream.default.producer.errorChannelEnabled=true
----

you can handle the error message in this way:

----
    // Replace destination with spring.cloud.stream.bindings.output.destination
    @ServiceActivator(inputChannel == "{destination}.errors")
    public void producerError(Message<?> message) {
        LOGGER.error("Handling Producer ERROR: " + message);
    }
----

===== Batch Consumer Sample

====== Configuration Options

To enable the batch consumer mode, you should add below configuration

[source,yaml]
----
spring:
  cloud:
    stream:
      bindings:
        consume-in-0:
          destination: {event-hub-name}
          group: [consumer-group-name]
          consumer:
            batch-mode: true 
      eventhubs:
        bindings:
          consume-in-0:
            consumer:
              checkpoint:
                mode: BATCH # or MANUAL as needed
              batch:
                max-size: 2 # The default value is 10
                max-wait-time: 1m # Optional, the default value is null
----

======= Consume messages in batches

For checkpointing mode as BATCH, you can use below code to send messages and consume in batches.

[source,java]
----
    @Bean
    public Consumer<List<String>> consume() {
        return list -> list.forEach(event -> LOGGER.info("New event received: '{}'",event));
    }
    @Bean
    public Supplier<Message<String>> supply() {
        return () -> {
            LOGGER.info("Sending message, sequence " + i);
            return MessageBuilder.withPayload("\"test"+ i++ +"\"").build();
        };
    }
----

For checkpointing mode as MANUAL, you can use below code to send messages and consume/checkpoint in batches.

[source,java]
----
    @Bean
    public Consumer<Message<List<String>>> consume() {
        return message -> {
            for (int i == 0; i < message.getPayload().size(); i++) {
                LOGGER.info("New message received: '{}', partition key: {}, sequence number: {}, offset: {}, enqueued time: {}",
                    message.getPayload().get(i),
                    ((List<Object>) message.getHeaders().get(EventHubsHeaders.PARTITION_KEY)).get(i),
                    ((List<Object>) message.getHeaders().get(EventHubsHeaders.SEQUENCE_NUMBER)).get(i),
                    ((List<Object>) message.getHeaders().get(EventHubsHeaders.OFFSET)).get(i),
                    ((List<Object>) message.getHeaders().get(EventHubsHeaders.ENQUEUED_TIME)).get(i));
            }
        
            Checkpointer checkpointer == (Checkpointer) message.getHeaders().get(CHECKPOINTER);
            checkpointer.success()
                        .doOnSuccess(success -> LOGGER.info("Message '{}' successfully checkpointed", message.getPayload()))
                        .doOnError(error -> LOGGER.error("Exception found", error))
                        .subscribe();
        };
    }
    @Bean
    public Supplier<Message<String>> supply() {
        return () -> {
            LOGGER.info("Sending message, sequence " + i);
            return MessageBuilder.withPayload("\"test"+ i++ +"\"").build();
        };
    }
----

=== Spring Cloud Stream Binder for Azure Service Bus

==== Dependency Setup

[source,xml]
----
<dependency>
	<groupId>com.azure.spring</groupId>
	<artifactId>spring-cloud-azure-stream-binder-servicebus</artifactId>
</dependency>
----

==== Configuration

The binder provides the following configuration options:

===== Spring Cloud Azure Properties

[cols="<,<,<,<"]
|===
|Name |Description |Required |Default

|spring.cloud.azure.auto-create-resources |If enable auto-creation for Azure resources | |false
|spring.cloud.azure.region |Region name of the Azure resource group, e.g. westus |Yes if spring.cloud.azure.auto-create-resources is enabled. 
|spring.cloud.azure.environment |Azure Cloud name for Azure resources, supported values are `azure`, `azurechina`, `azure_germany` and `azureusgovernment` which are case insensitive | |azure 
|spring.cloud.azure.client-id |Client (application) id of a service principal or Managed Service Identity (MSI) |Yes if service principal or MSI is used as credential configuration. 
|spring.cloud.azure.client-secret |Client secret of a service principal |Yes if service principal is used as credential configuration. 
|spring.cloud.azure.msi-enabled |If enable MSI as credential configuration |Yes if MSI is used as credential configuration. |false
|spring.cloud.azure.resource-group |Name of Azure resource group |Yes if service principal or MSI is used as credential configuration. 
|spring.cloud.azure.subscription-id |Subscription id of an MSI |Yes if MSI is used as credential configuration. 
|spring.cloud.azure.tenant-id |Tenant id of a service principal |Yes if service principal is used as credential configuration. 
|spring.cloud.azure.servicebus.connection-string |Service Bus Namespace connection string |Yes if connection string is used as credential configuration 
|spring.cloud.azure.servicebus.namespace |Service Bus Namespace. Auto creating if missing |Yes if service principal or MSI is used as credential configuration. 
|spring.cloud.azure.servicebus.transportType |Service Bus transportType, supported value of `AMQP` and `AMQP_WEB_SOCKETS` |No |`AMQP`
|spring.cloud.azure.servicebus.retry-Options |Service Bus retry options |No |Default value of AmqpRetryOptions
|===

===== Partition configuration

The system will obtain the parameter `PartitionSupply` to send the message.

The following are configuration items related to the producer:

*_partition-count_*

The number of target partitions for the data, if partitioning is enabled.

Default: 1

*_partition-key-extractor-name_*

The name of the bean that implements `PartitionKeyExtractorStrategy`.
The partition handler will first use the `PartitionKeyExtractorStrategy#extractKey` method to obtain the partition key value.

Default: null

*_partition-key-expression_*

A SpEL expression that determines how to partition outbound data.
When interface `PartitionKeyExtractorStrategy` is not implemented, it will be called in the method `PartitionHandler#extractKey`.

Default: null

For more information about setting partition for the producer properties, please refer to the https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html#_producer_properties[Producer Properties of Spring Cloud Stream].

===== Serivce Bus Queue Producer Properties

It supports the following configurations with the format of `spring.cloud.stream.servicebus.queue.bindings.&lt;channelName&gt;.producer`.

*_sync_*

Whether the producer should act in a synchronous manner with respect to writing messages into a stream. If true, the
producer will wait for a response after a send operation.

Default: `false`

*_send-timeout_*

Effective only if `sync` is set to true. The amount of time to wait for a response after a send operation, in milliseconds.

Default: `10000`

===== Service Bus Queue Consumer Properties

It supports the following configurations with the format of `spring.cloud.stream.servicebus.queue.bindings.&lt;channelName&gt;.consumer`.

*_checkpoint-mode_*

The mode in which checkpoints are updated.

`RECORD`, checkpoints occur after each record successfully processed by user-defined message handler without any exception.

`MANUAL`, checkpoints occur on demand by the user via the `Checkpointer`. You can get `Checkpointer` by `Message.getHeaders.get(AzureHeaders.CHECKPOINTER)`callback.

Default: `RECORD`

*_prefetch-count_*

Prefetch count of underlying service bus client.

Default: `1`

*_maxConcurrentCalls_*

Controls the max concurrent calls of service bus message handler and the size of fixed thread pool that handles user's business logic

Default: `1`

*_maxConcurrentSessions_*

Controls the maximum number of concurrent sessions to process at any given time.

Default: `1`

*_concurrency_*

When `sessionsEnabled` is true, controls the maximum number of concurrent sessions to process at any given time.
When `sessionsEnabled` is false, controls the max concurrent calls of service bus message handler and the size of fixed thread pool that handles user's business logic.

Deprecated, replaced with `maxConcurrentSessions` when `sessionsEnabled` is true and `maxConcurrentCalls` when `sessionsEnabled` is false

Default: `1`

*_sessionsEnabled_*

Controls if is a session aware consumer. Set it to `true` if is a queue with sessions enabled.

Default: `false`

*_requeueRejected_*

Controls if is a message that trigger any exception in consumer will be force to DLQ.
Set it to `true` if a message that trigger any exception in consumer will be force to DLQ.
Set it to `false` if a message that trigger any exception in consumer will be re-queued.

Default: `false`

*_receiveMode_*

The modes for receiving messages.

`PEEK_LOCK`, received message is not deleted from the queue or subscription, instead it is temporarily locked to the receiver, making it invisible to other receivers.

`RECEIVE_AND_DELETE`, received message is removed from the queue or subscription and immediately deleted.

Default: `PEEK_LOCK`

*_enableAutoComplete_*

Enable auto-complete and auto-abandon of received messages.
'enableAutoComplete' is not needed in for RECEIVE_AND_DELETE mode.

Default: `false`

===== Support for Service Bus Message Headers and Properties

The following table illustrates how Spring message headers are mapped to Service Bus message headers and properties.
When create a message, developers can specify the header or property of a Service Bus message by below constants.

For some Service Bus headers that can be mapped to multiple Spring header constants, the priority of different Spring headers is listed.

|===
|Service Bus Message Headers and Properties |Spring Message Header Constants |Type |Priority Number (Descending priority)

|*MessageId* |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.MESSAGE_ID |String |1
|*MessageId* |com.azure.spring.integration.core.AzureHeaders.RAW_ID |String |2
|*MessageId* |org.springframework.messaging.MessageHeaders.ID |UUID |3
|ContentType |org.springframework.messaging.MessageHeaders.CONTENT_TYPE |String |N/A
|ReplyTo |org.springframework.messaging.MessageHeaders.REPLY_CHANNEL |String |N/A
|*ScheduledEnqueueTimeUtc* |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.SCHEDULED_ENQUEUE_TIME |OffsetDateTime |1
|*ScheduledEnqueueTimeUtc* |com.azure.spring.integration.core.AzureHeaders.SCHEDULED_ENQUEUE_MESSAGE |Integer |2
|TimeToLive |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.TIME_TO_LIVE |Duration |N/A
|SessionID |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.SESSION_ID |String |N/A
|CorrelationId |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.CORRELATION_ID |String |N/A
|To |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.TO |String |N/A
|ReplyToSessionId |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.REPLY_TO_SESSION_ID |String |N/A
|*PartitionKey* |com.azure.spring.integration.servicebus.converter.ServiceBusMessageHeaders.PARTITION_KEY |String |1
|*PartitionKey* |com.azure.spring.integration.core.AzureHeaders.PARTITION_KEY |String |2
|===

For full configurations, check appendix

==== Basic Usage

==== Samples

*Example: Manually set the partition key for the message*

This example demonstrates how to manually set the partition key for the message in the application.

*Way 1:*
This example requires that `spring.cloud.stream.default.producer.partitionKeyExpression` be set `&quot;&#39;partitionKey-&#39; + headers[&lt;message-header-key&gt;]&quot;`.

[source,yaml]
----
spring:
  cloud:
    azure:
      servicebus:
        connection-string: [servicebus-namespace-connection-string]
    stream:
      default:
        producer:
          partitionKeyExpression:  "'partitionKey-' + headers[<message-header-key>]"
----

[source,java]
----
@PostMapping("/messages")
public ResponseEntity<String> sendMessage(@RequestParam String message) {
    LOGGER.info("Going to add message {} to Sinks.Many.", message);
    many.emitNext(MessageBuilder.withPayload(message)
                                .setHeader("<message-header-key>", "Customize partirion key")
                                .build(), Sinks.EmitFailureHandler.FAIL_FAST);
    return ResponseEntity.ok("Sent!");
}
----

____

*NOTE:* When using `application.yml` to configure the partition key, its priority will be the lowest.
It will take effect only when the `ServiceBusMessageHeaders.SESSION_ID`, `ServiceBusMessageHeaders.PARTITION_KEY`, `AzureHeaders.PARTITION_KEY` are not configured.
*Way 2:*
Manually add the partition Key in the message header by code.

____

_Recommended:_ Use `ServiceBusMessageHeaders.PARTITION_KEY` as the key of the header.

[source,java]
----
@PostMapping("/messages")
public ResponseEntity<String> sendMessage(@RequestParam String message) {
    LOGGER.info("Going to add message {} to Sinks.Many.", message);
    many.emitNext(MessageBuilder.withPayload(message)
                                .setHeader(ServiceBusMessageHeaders.PARTITION_KEY, "Customize partirion key")
                                .build(), Sinks.EmitFailureHandler.FAIL_FAST);
    return ResponseEntity.ok("Sent!");
}
----

_Not recommended but currently supported:_ `AzureHeaders.PARTITION_KEY` as the key of the header.

[source,java]
----
@PostMapping("/messages")
public ResponseEntity<String> sendMessage(@RequestParam String message) {
    LOGGER.info("Going to add message {} to Sinks.Many.", message);
    many.emitNext(MessageBuilder.withPayload(message)
                                .setHeader(AzureHeaders.PARTITION_KEY, "Customize partirion key")
                                .build(), Sinks.EmitFailureHandler.FAIL_FAST);
    return ResponseEntity.ok("Sent!");
}
----

____

*NOTE:* When both `ServiceBusMessageHeaders.PARTITION_KEY` and `AzureHeaders.PARTITION_KEY` are set in the message headers,
`ServiceBusMessageHeaders.PARTITION_KEY` is preferred.
*Example: Set the session id for the message*

____

This example demonstrates how to manually set the session id of a message in the application.

[source,java]
----
@PostMapping("/messages")
public ResponseEntity<String> sendMessage(@RequestParam String message) {
    LOGGER.info("Going to add message {} to Sinks.Many.", message);
    many.emitNext(MessageBuilder.withPayload(message)
                                .setHeader(ServiceBusMessageHeaders.SESSION_ID, "Customize session id")
                                .build(), Sinks.EmitFailureHandler.FAIL_FAST);
    return ResponseEntity.ok("Sent!");
}
----

____

*NOTE:* When the `ServiceBusMessageHeaders.SESSION_ID` is set in the message headers, and a different `ServiceBusMessageHeaders.PARTITION_KEY` (or `AzureHeaders.PARTITION_KEY`) header is also set,
the value of the session id will eventually be used to overwrite the value of the partition key.
Please use this `sample` as a reference to learn more about how to use this binder in your project.
- https://github.com/Azure-Samples/azure-spring-boot-samples/tree/main/servicebus/azure-spring-cloud-stream-binder-servicebus-queue[Service Bus Queue]

____

